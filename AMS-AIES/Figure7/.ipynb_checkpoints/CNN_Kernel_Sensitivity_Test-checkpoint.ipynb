{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3531a75e-9478-45f0-956e-08884f04c31c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1D Convolutional Neural Network - Kernel Sensitivity \n",
    "This is code of the 1D CNN model kernel sensitivity test. This code trains the CNN model for each combination of Kernels. \\\n",
    "Calculates RMSE and IOA and saves to a text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4264799-b6c7-4c77-aed5-cb084994dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import multiprocessing\n",
    "import xarray as xr\n",
    "\n",
    "from pyISV.utils import remove_partial_year, check_nan, calc_anomalies, calc_lanczos_filtered_anomalies\n",
    "from pyISV.cnn import wrapper_cnn_bpf, check_system_capabilities, split_dataset_cnn\n",
    "from pyISV.metrics import calc_save_rmse_ioa_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e1e9d2-8d7a-4cd4-b470-c6a0eda63a18",
   "metadata": {},
   "source": [
    "#### Load interpolated NOAA OLR \n",
    "The interpolated OLR data is downloaded from: \\\n",
    "https://downloads.psl.noaa.gov/Datasets/interp_OLR/olr.day.mean.nc \\\n",
    "For convenince, OLR files are renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d1f26-b893-4073-b9ae-426cfaef5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA interpolated daily mean OLR\n",
    "olriFile = 'olr.day.interpolated.mean.nc'\n",
    "olri = xr.open_dataset(olriFile).olr\n",
    "olri = olri.reindex(lat=olri.lat[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68aa4c-7a6a-4897-bbd2-78832344ced3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Enter latitude and longitude bounds of the domain and slice the OLR within the domain\n",
    "Check for NaNs. The input data should not contain NaNs. Replace the NaNs if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6bbcb-0ab3-458e-b1ea-38a9296aa90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_south, lat_north, long_west, long_east = -7.5, 7.5, 125, 270\n",
    "olri = olri.sel(lat=slice(lat_south,lat_north),lon=slice(long_west,long_east),time=slice('1980',None))\n",
    "# Check if the input data contains any NaNs. Get the location indices of NaNs if present.\n",
    "nan_indices = check_nan(olri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4858a79-be88-4634-ba42-e08b2e0b650b",
   "metadata": {},
   "source": [
    "#### Get the years to split the dataset into training, validation, and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a379c254-1afa-485a-9ad2-52a143d9bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "startTrain, endTrain, startVal, endVal, startTest, endTest = '1988', '2012', '2013', '2014', '2015', '2016'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe7adf-f8f1-40ef-b42d-71de765503e0",
   "metadata": {},
   "source": [
    "#### Calculate climatology, anomalies, and 30-90-day band pass filtered anomalies\n",
    "\n",
    "Calculate climatology based only on the training period. This will avoid test data leakages or bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a860f-7a2a-4221-8745-9c331d14fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwgths, tpa, tpb, filt_type  = 90, 30, 90, 'band' # The filter uses 181 (nwgths*2+1) weights; tpa, tpb: Time period\n",
    "\n",
    "olri_anom, _ = calc_anomalies(olri, startTrain, endTrain, smooth_climatology=False)\n",
    "olri_bpf = calc_lanczos_filtered_anomalies(olri_anom, nwgths, filt_type, tpa, tpb)\n",
    "\n",
    "# Select the same time period for the unfiltered anomalies as the filtered anomalies\n",
    "olri_anom = olri_anom.sel(time=slice(olri_bpf.time[0], olri_bpf.time[-1]))\n",
    "\n",
    "# Remove the partial year data\n",
    "olri_bpf = remove_partial_year(olri_bpf)\n",
    "olri_anom = remove_partial_year(olri_anom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52392326-bea0-4156-8142-561a100ceb42",
   "metadata": {},
   "source": [
    "#### Check system hardware capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573b690-b3f5-4d5d-8e40-bf19a2e1ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_system_capabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20e26a-6bbc-4f82-a394-8ebef172e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter below the number of cores (cpus) to be alloted for parallel processing\n",
    "num_cpus = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7645bc3-22dc-43e4-9624-27e5870a450e",
   "metadata": {},
   "source": [
    "#### Split the dataset into training, validation, and testing sets for a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65faecf4-cf36-4d6f-9556-6831d0618a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_split, ytrain_split, xval_split, yval_split, xtest_split, ytest, ngp = split_dataset_cnn(\n",
    "    startTrain, endTrain, startVal, endVal, startTest, endTest, olri_anom, olri_bpf, num_cpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b5e0e-c4f3-4bd6-920e-2f788e938d96",
   "metadata": {},
   "source": [
    "#### Train the CNN model for eack kernel combinations, calculate RMSE and IOA, and save to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17693524-824b-4df0-a48a-3f713351ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model weights are not saved. so set it None\n",
    "outPath = None\n",
    "\n",
    "kernel1 = np.arange(60, 130, 10).tolist()\n",
    "kernel2 = np.arange(10, 70, 10).tolist() \n",
    "\n",
    "no_epochs = 500\n",
    "verbosity = 0\n",
    "var_name = 'olr'\n",
    "  \n",
    "# Define the arguments for each process\n",
    "for k1 in kernel1:\n",
    "\n",
    "    for k2 in kernel2:\n",
    "\n",
    "        print(f\"Kernel1: {k1}, kernel2: {k2}\")\n",
    "\n",
    "        arguments = [(cc, xtrain_split, ytrain_split, xval_split, yval_split, xtest_split, no_epochs, verbosity, k1, k2, ngp, outPath) for cc in range(num_cpus)]\n",
    "\n",
    "        with multiprocessing.Pool(processes=num_cpus) as pool:\n",
    "            results = np.hstack(pool.map(wrapper_cnn_bpf, arguments))\n",
    "\n",
    "        calc_save_rmse_ioa_text(results, ytest)\n",
    "        \n",
    "        del results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "package",
   "language": "python",
   "name": "package"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
